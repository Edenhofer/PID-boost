\chapter{Analysis}
\label{chap:analysis}

\section{Data sample}
\label{sec:data_sample}

In order to validate a particle identification approach and to make sure it is behaving as expected, it is good practice to measure the performance on Monte Carlo simulated data. The software framework EvtGen is used for the purpose of simulating the production and the decay of the $\Upsilon(4S)$. The subsequent generic decay is simulated using decay files provided by the Belle~\RN{2} software. After the simulation of the particle and their various properties, the detector responses are emulated. Hits in the various detector components are simulated and finally the veracity of a track identification is calculated. The process of matching the identification with the truth is not possible for real data, as the true property of a particle are not known in the experiment. However, for testing purposes it is a valuable tool as it allows to compare the performance of new approachs.

Throughout the thesis several decays are discussed, most notably the decay of the charged $B$ mesons. $\Upsilon(4S)$ decays in $(51.4 \pm 0.6) \%$ of cases into the charged $B^+$ and $B^-$. Therefore it represents a good sample of the overall to be expected particle species. Observations seen in this generic charged decay were validated using data of the `mixed' decay of the $B$ meson into $B^0$ and $\bar{B}^0$ which has a branching ratio of $(48.6 \pm 0.6) \%$. Both samples are generic decays and not specific to one analysis. A complete list of possible decay-strings as well as the above mentioned branching fractions can be found in~\cite{Patrignani:2016xqp}.

Additionally a simulated decay of the $B^+ B^-$ with non-generic properties is generated. Its properties are outlined in \autoref{tab:simulated_decay}. It allows for a fast processing of tests due to its simplicity and helps in differentiating between decay specific observations and generic ones. The data from this decay is not used for visualizations as it does not translate to an application in the real world.

\begin{table}[ht]
	\centering
	\begin{tabular}{l|l}
		Decay string & Branching ratio \\
		\hline
		$\Upsilon(4S) \rightarrow B^+ B^-$ & $1.$ \\
		\quad $B^+ \rightarrow \mu^+ \nu_{\mu} \gamma$ & $1.$ \\
		\quad $B^- \rightarrow \pi^- D^0$ & $1.$ \\
		\qquad $D^0 \rightarrow K^- \pi^+$ & $0.2$ \\
		\qquad 	$D^0 \rightarrow K^- \pi^+ \pi^0$ & $0.2$ \\
		\qquad 	$D^0 \rightarrow K^- \pi^+ \pi^+ \pi^-$ & $0.2$ \\
		\qquad 	$D^0 \rightarrow K^- K^+$ & $0.2$ \\
		\qquad 	$D^0 \rightarrow \pi^+ \pi^0$ & $0.2$ \\
	\end{tabular}
	\caption{Simulated non-generic decay of the $\Upsilon(4S)$ with charge conjugated decays implied.}
	\label{tab:simulated_decay}
\end{table}

As seen in \autoref{fig:true_particle_abundance} the decays are dominated by kaons and pions. However the overall distribution is much more peaked for the charged generic decay. Furthermore the non-generic sample decay features a feature a lot more $\mu^+$ relatively speaking in comparison charged generic decay. The mixed generic decay is disregarded for this plot due to its distinct similarity to the charged decay.

\begin{figure}[ht]
	\centering
	\subcaptionbox{Charged\label{fig:charged_decay_true_particle_abundance}}{
		\includegraphics[width=0.43\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/General Purpose Statistics: True Particle Abundances in the K+-Data}}}
	}
	\hspace{2em}
	\subcaptionbox{Sample\label{fig:sample_decay_true_particle_abundance}}{
		\includegraphics[width=0.43\textwidth,height=\textheight,keepaspectratio]{{{../res/sample/General Purpose Statistics: True Particle Abundances in the K+-Data}}}
	}
	\caption{True particle abundance in various simulated decays with particle on the $x$-axis sorted by their frequency. \textit{NaN} stands for an invalid translation\protect\footnotemark from the particles' PDG code to an actual particle.}
	\label{fig:true_particle_abundance}
\end{figure}
\footnotetext{The error occurs due to the PDG code in the ROOT file being saved as \lstinline|float32|. However, some particle's code exceed the memory limit of $32$-bits. Notably this effects the deuteron and its anti-particle.}

Prior to evaluating the data, it is stripped of falsely identified and poorly defined tracks. First the transverse momentum is limited to the range of $0.0$ to $5.29$. This removes very slow and very fast particles as both provide very badly described tracks. Next, the transverse distance of the closest point of the track to the point of interaction is limited to $2 \mathrm{~cm}$, respectively $5 \mathrm{~cm}$ for the longitudinal distance. Lastly, tracks with no assigned PDG code are pruned. Such tracks are considered falsely reconstructed as a majority of hits of the track do not belong to the true simulated track. Including those kinds of tracks would have suggested the particle identification process shall identify non-particles tracks. Overall the effect of tracks with no PDG code does not influence the final result in any significant way. The tracks were merely excluded for the purpose of clarity.

The generic decay files are used in the following discussion. Each decay file features $100,000$ initial $B \bar{B}$ events and about ten times as many identified tracks. The non-generic decay contains $10,000$ initial events and about $40,000$ tracks.

If not specifically otherwise stated it can be assumed that the graphs and visuals in the following paragraphs are based on the data from one generic charged decay file. The number of samples in one such file is sufficiently high for the purpose of the study while still providing acceptable performance.

\section{Particle identification variables}
\label{sec:pid_variables}

\subsection{Legacy PID}
\label{subsec:pid_variables_legacy_pid}

The current particle identification approach consists of variables calculated via ratios of likelihoods. A particle identification is performed by applying a selection, also called \textit{cut} on the variables.

As of \formatdate{28}{06}{2018}, the current approach is to take the likelihood of the desired particle and divide it by itself plus the likelihood of the pion. To construct the ID of the pion the kaon likelihood is used as second summand in the denominator. \autoref{tab:legacy_particleid_variables} shows the definition of the ID for each of the six particle species of interest. In the future it will be replaced by the global PID approach, described in \autoref{subsec:pid_variables_global_pid}.

\begin{table}[ht]
	\centering
	\begin{tabular}{l|l}
		pionID & $\mathcal{L}_{\pi} / (\mathcal{L}_{\pi} + \mathcal{L}_{K})$ \\
		kaonID & $\mathcal{L}_{K} / (\mathcal{L}_{K} +\mathcal{L}_{\pi})$ \\
		protonID & $\mathcal{L}_{p} / (\mathcal{L}_{p} +\mathcal{L}_{\pi})$ \\
		electronID & $\mathcal{L}_{e} / (\mathcal{L}_{e} +\mathcal{L}_{\pi})$ \\
		muonID & $\mathcal{L}_{\mu} / (\mathcal{L}_{\mu} +\mathcal{L}_{\pi})$ \\
		deuteronID & $\mathcal{L}_{d} / (\mathcal{L}_{d} +\mathcal{L}_{\pi})$
	\end{tabular}
	\caption{Definition of the ParticleID variables currently used by default for particle identification.}
	\label{tab:legacy_particleid_variables}
\end{table}

The identification efficiencies for pions and kaons are rather good as the approach is able to properly differentiate both classes. However it has obvious limitations in identifying rare particles as the fraction is dominated by the high abundance of the pion.

The difference in the TPR for identifying the pions and the electron can be seen in \autoref{fig:legacy_pid_particle_identification}. The pions is used as a representative of a particle specie with a high abundance, while the electron is one of the low abundance particle species. A high efficiency in selecting the particles is achieved quickly. However, the purity of the sample clearly underlines the preference towards the pion identification.

\begin{figure}[ht]
	\centering
	\subcaptionbox{Pion identification\label{fig:legacy_pid_pions_identification}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Particle ID Approach: pi Identification}}}
	}
	\hspace{2em}
	\subcaptionbox{Electron identification\label{fig:legacy_pid_electron_identification}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Particle ID Approach: e Identification}}}
	}
	\caption{Particle identification rates for the pions and electron using the legacy PID approach, each showing the True Positive Rate (ROC curve) and the Positive Predicted Value depending on the False Positive Rate.}
	\label{fig:legacy_pid_particle_identification}
\end{figure}

This unbalanced classification is further emphasized by analyzing the identification efficiencies. The matrix shown in~\autoref{fig:legacy_pid_epsilon_pid} clearly highlights the bias of the classification towards kaons and pions. There is a high chance of a particle being identified as kaon or pion, regardless of the actual particle's identity.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.3\textheight,keepaspectratio]{{{../res/charged 01/Particle ID Approach: Heatmap of epsilonPID Matrix for an exclusive Cut}}}
	\caption{Matrix of $\epsilon$ values for the legacy particle ID approach.}
	\label{fig:legacy_pid_epsilon_pid}
\end{figure}

\subsection{global PID}
\label{subsec:pid_variables_global_pid}

The global PID approach is the upcoming approach which is to be used as new default variable on which to select particle samples. Instead of having the likelihood of the pion fixed in the denominator of every particle's id, it is replaced by the sum over all the other particles. Hence, the global PID of the kaon is now represented by the likelihood of the kaon divided by sum of all the likelihoods of every other particle including the kaon itself. The complete list of the definition can be seen in \autoref{tab:global_pid_variables}.

\begin{table}[ht]
	\centering
	\begin{tabular}{l|l}
		globalPionID & $\mathcal{L}_{\pi} / \mathcal{L}_{all}$ \\
		globalKaonID & $\mathcal{L}_{K} / \mathcal{L}_{all}$ \\
		globalProtonID & $\mathcal{L}_{p} / \mathcal{L}_{all}$ \\
		globalElectronID & $\mathcal{L}_{e} / \mathcal{L}_{all}$ \\
		globalMuonID & $\mathcal{L}_{\mu} / \mathcal{L}_{all}$ \\
		globalDeuteronID & $\mathcal{L}_{d} / \mathcal{L}_{all}$ \\
		\hline
		\multicolumn{2}{c}{$\mathcal{L}_{all} = \sum \limits_{x \in {\pi, K, p, e, \mu, d}} \mathcal{L}_{x}$}
	\end{tabular}
	\caption{Definition of the globalPID variables which is to be used by default for particle identification in the future.}
	\label{tab:global_pid_variables}
\end{table}

The approach is significantly less prone to merely differentiating between kaons and pions but instead has a more balanced classification as can be seen in \autoref{fig:global_pid_epsilon_pid}. This newly gained efficiency in identifying particles of lower abundance comes at the cost of worsening the classification of particles of high abundance. Both the kaon and the pion are less likely to be correctly identified, with the pion efficiency taking an especially steep decline.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.3\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Heatmap of epsilonPID Matrix for an exclusive Cut}}}
	\caption{Matrix of $\epsilon$ values for the global PID approach.}
	\label{fig:global_pid_epsilon_pid}
\end{figure}

\subsection{Goodness of the global PID variables}
\label{subsec:pid_variables_global_pid_goodness}

In order to ensure the global PID variables are properly defined, a likelihood ratio test based on the Neyman-Pearson lemma as outlined in \autoref{subsec:likelihood_ratios_neyman_pearson} is used. The lemma states that the highest purity for a given efficiency is to be expected for each selection on the likelihood ratio as seen in \autoref{fig:neyman_pearson_visualization}.

For the following analysis the data is sampled into $10$ bins of equal height as to provide a balanced statistics for each bin. The error in a bin is given by a vertical line. It is calculated via gaussian error propagation under the assumption that the counting of the events follow a Poisson distribution. Thereby assumption is made that the number of desired particles in a bin and the number of undesired particles are independent. The error is underestimated for a purity of $0$ and $1$.

When applying the previously discussed approach to the data, the goodness of the likelihoods can be validated as seen in \autoref{fig:likelihood_ratio_kaon_all}. The purity of the kaon sample in the bins increases with a stricter likelihood cut and the uncertainty is low due to the high statistics. However \autoref{fig:likelihood_ratio_proton_all} paints a completely different picture. The purity peaks at a likelihood ratio of about $0.35$, while the following values are far lower. However this effect is unique to the proton and can not be observed in any other of the six particle species of interest. On one hand this means the likelihoods for the kaon, pion, electron, muon and deuteron are properly defined and actually behave like probabilities. On the other hand it also reveals a flaw in the calculation of the proton likelihood. Thankfully the proton does not play a significant role in the analysis done in the following sections but nevertheless it is important to keep in mind that identifying protons via their likelihood (likelihood ratio) has inherent flaws.

\begin{figure}[ht]
	\centering
	\subcaptionbox{Kaon\label{fig:likelihood_ratio_kaon_all}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative K Abundance in Likelihood Ratio Bins for ALL detector}}}
	}
	\hspace{2em}
	\subcaptionbox{Proton\label{fig:likelihood_ratio_proton_all}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for ALL detector}}}
	}
	\caption{Relative abundance (purity) of various particle samples in likelihood ratio bins.}
	\label{fig:likelihood_ratio_all}
\end{figure}

In order to understand the observed effect in \autoref{fig:likelihood_ratio_proton_all} it is important to pin down its cause. Since the likelihoods are values which are returned by each detector, a natural conclusion might be that it is caused by one poorly defined detector response. \autoref{fig:likelihood_ratio_proton_by_detector} shows the relative abundance of the proton in likelihood ratio bins for various detector components.

\begin{figure}[ht]
	\centering
	\subcaptionbox{SVD\label{fig:likelihood_ratio_proton_svd}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative K Abundance in Likelihood Ratio Bins for SVD detector}}}
	}
	\hspace{0.5em}
	\subcaptionbox{CDC\label{fig:likelihood_ratio_proton_cdc}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for CDC detector}}}
	}
	\hspace{0.5em}
	\subcaptionbox{TOP\label{fig:likelihood_ratio_proton_top}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for TOP detector}}}
	}

	\subcaptionbox{ARICH\label{fig:likelihood_ratio_proton_arich}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for ARICH detector}}}
	}
	\hspace{0.5em}
	\subcaptionbox{ECL\label{fig:likelihood_ratio_proton_ecl}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for ECL detector}}}
	}
	\hspace{0.5em}
	\subcaptionbox{KLM\label{fig:likelihood_ratio_proton_klm}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for KLM detector}}}
	}

	\caption{Relative abundance (purity) of the proton in likelihood ratio bins for all available detectors.}
	\label{fig:likelihood_ratio_proton_by_detector}
\end{figure}

The response of the SVD is in perfect agreement with the expectation. However, the CDC shows the same kink merely shifted a little to the left. The TOP is in agreement again. The ARICH, ECL and KLM have an insufficient statistics and/or the likelihoods do not fil the whole range. The error is underestimate at multiple points close to a purity of $0$. Hence the ECL seems like the only viable cause of the unexpected kink in the proton purity over likelihood ratio plot. The observed shift to the left is due to the likelihood of a single detector in general being lower than the  likelihood of all detectors combined.

Next, the $p_t$ dependency in the CDC detector was analysed as depicted in \autoref{fig:likelihood_ratio_proton_by_pt}. As sampling method three equal height bins are chosen. Using rather few bins with the same number of particles in each one, provides good statistics and allows for fair comparisons. Analyzing the picture, it becomes obvious that especially low to medium transverse momentum protons constitute to the effect.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.5\textheight,keepaspectratio]{{{../res/charged 01/pidProbability Approach: Relative p Abundance in Likelihood Ratio Bins for CDC detector for equal size pt bins}}}
	\caption{Relative abundance of the proton in likelihood ratio bins for different transverse momentum ranges in units of $GeV/c$ for the CDC detector.}
	\label{fig:likelihood_ratio_proton_by_pt}
\end{figure}

Furthermore it is important to bear the locations of the detector components in mind. Of special interest in this case is the end of the TOP detector, at roughly $(- 60^{\circ})$ relative to the beampipe (see~\autoref{fig:belle2_detector_design_white_paper}). At this point the particle identification gets notably different. However, as this effects all tracks equally for $p_t$ bins it cancels out in comparisons. The effect becomes important for equal height bins of the angle.

In conclusion the likelihood of the proton returned by the CDC detector should be seen with healthy skepticism and not be taken for granted as it does not behave as a likelihood. Further analysis needs to take place in order to pin down the actual cause.

\section{Bayesian approach}
\label{sec:bayesian_approach}

\subsection{Simple Bayes}
\label{subsec:bayesian_approach_simple_bayes}

The goal of a Bayesian approach is to weight the particles' probability by their abundance in the sample. This process increases the likelihood of a particle being identified as belonging to a group with a higher abundance and decreases the likelihood of being identified as belonging to a group with a lower abundance. Bayes theorem provides the mathematical foundation:
\begin{equation*}
	\displaystyle P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
	\text{,}
	\qquad
	\text{e.g.,} \quad P(e|Signal) = \frac{P(Signal|e) \cdot P(e)}{P(Signal)}.
\end{equation*}
The variable $P(e|Signal)$ is the probability of the track being from an electron given that $Signal$ is measured. The part of most interest in the equation is the a priori probability $P(A)$, respectively $P(e)$. As a first simple approach this variable is now dependant on the absolute abundance of electrons. The probability of detecting the signal is modeled using
\begin{equation*}
	P(Signal) = \sum \limits_{x \in {\pi, K, p, e, \mu, d}} P(Signal|x) \cdot P(x)
\end{equation*}
with $P(Signal|x)$ being the previously discussed likelihoods of the signal using the particle hypothesis $x$. Note that the absolute normalization of $P(x)$ cancels out as it occurs in both nominator and denominator. Therefore, it makes no difference if the value of the abundance is used directly as $P(x)$ in the calculation.

The absolute particle abundance of a sample taken from the Monte Carlo simulation of the charged decay of the $B$-mesons can be seen in \autoref{fig:charged_decay_true_particle_abundance}. In this example the bias towards pions and kaons can be clearly observed.

The approach depends on the detector yielding decay-agnostic results. Hence the detector shall be assumed to always output the likelihood of measuring the received signal given a specific particle hypothesis regardless of prior probabilities. Furthermore the approach assumes a bias towards one or a few particles in the data since otherwise the a priori probabilities would be flat and would have no effect.
Thankfully both of those hypothesis are fulfilled in the real world: The detector can be assumed to behave independently of the relative particle abundance and the measured data shows a clear predominance of one or a few particle species. This is not surprising in itself as the branching fractions are not equally distributed.

\subsection{Univariate Bayes}
\label{subsec:bayesian_approach_univariate_bayes}

The univariate Bayesian approach adds a further dependency in the form of a detector variable to the a priori probabilities of the Bayesian approach. Hence, instead of having a priori probability which depends only on the particle overall abundance, the univariate approach additionally varies the value. Namely the abundance is made dependant on, e.g., the transverse momentum and the angle between the beampipe and track $\Theta$ are considered. Those two variables make the most sense as they play a significant role in the track fitting process and are dominant factors for the particle classification process outlined in~\autoref{subsec:particle_identification}.

\begin{figure}[ht]
	\centering
	\subcaptionbox{$p_t$\label{fig:univariate_bayes_priors_by_pt}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Univariate Bayesian Approach: K Spectra Ratios Relative to pi for pt bins}}}
	}
	\hspace{2em}
	\subcaptionbox{$\cos(\Theta)$\label{fig:univariate_bayes_priors_by_costheta}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Univariate Bayesian Approach: K Spectra Ratios Relative to pi for cos(Theta) bins}}}
	}
	\caption{Kaon abundance relative to the pion abundance in equal height bins of $p_t$ and $\cos(\Theta)$ with horizontal lines indicating the size of each bin.}
	\label{fig:univariate_bayes_priors}
\end{figure}

The relative abundance of one particle in comparison to the pion is shown in \autoref{fig:univariate_bayes_priors}. Equal height bins were chosen to enforce a good statistics across all bins. The abundance relative to the pion is used in order to introduce a point of reference. The pion as such reference point is chosen arbitrarily. As previously discussed, the absolute normalization of the a priori probabilities does not matter. The graphs underline the motivation for using such an approach as the abundance varies between different bins. Especially the dependency on $p_t$ reveals drastic changes in the relative frequency of the kaon. Overall binning by $p_t$ reveals steeper contrasts and therefore is used as default binning method.

Due to its additional dependency the univariate Bayesian approach is able to adapt to the underlying data a little better in comparison to the Bayesian approach.

\subsection{Multivariate Bayes}
\label{subsec:bayesian_approach_multivariate_bayes}

The multivariate approach extends the univariate one by further increasing the number of free parameters on which the a priori probabilities may depend on. As previously mentioned both $p_t$ and $\cos(\Theta)$ make for an excellent choice as default variables for said dependency. Those variables provide a good separation between different particle species for certain pockets.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.5\textheight,keepaspectratio]{{{../res/charged 01/Multivariate Bayesian Approach: Multi-axes Histogram of pt, cosTheta for e, K, pi}}}
	\caption{Scatter plot with tracks represented as opaque points depending on $p_t$ and $\cos(\Theta)$. The color encodes the specie of the particle.}
	\label{fig:multivariate_bayes_multi_axis_histogram_by_pt_by_costheta}
\end{figure}

\autoref{fig:multivariate_bayes_multi_axis_histogram_by_pt_by_costheta}~shows tracks as transparent dots scattered across the plane, accompanied by two histograms showing the distribution in transverse momentum and the cosine of the angle between beampipe and track. It is important to note the sickle shape of the distribution. Higher values of the cosine are slightly preferred over lower ones due to the asymmetry of the beams. Furthermore the visual highlights the fact that angles of about $90^{\circ}$ ($\cos(\Theta) = 0$) correspond to the highest transverse momentums. In addition a slight separation between the yellow sickle on the left (pions), the cyan  in the middle (kaons) and the violet sickle on the right (electrons). The tail of the pion sickle extens beyond both kaons and electrons but it far less frequent. Intuitively this makes sense since as the production of a heavier particle\footnotemark consumes a more phase space which in turn reduces the amount of momentum it can carry. Analog, the electron is relatively speaking lightweight and therefore may carry a lot of momentum (not necessarily transverse momentum though). Obviously this interpretation disregards the fact that particles are not created one by one, but rather in a complex decay and the phase space is distributed across all daughters. Nevertheless, it illustrates the observed effect.
\footnotetext{Note, the mass of the kaon is about three and a half times higher than the mass of the pion.}

Enabling the a priori probability to depend on those measurements allows it to pick more fine grained priors. The a priori probabilities are estimated according using the Monte Carlo information for each combination of variables. In order to achieve this the variable $p_t$ and $\cos(\Theta)$ were distributed across equal height bins and the relative abundance of each particle relative to the pion were calculated for every combination of $p_t$ and $\cos(\Theta)$ bin.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.5\textheight,keepaspectratio]{{{../res/charged 01/Multivariate Bayesian Approach: K Spectra Ratios Relative to pi}}}
	\caption{Relative kaon abundance in equal height transverse momentum and cosine of $\Theta$ bins.}
	\label{fig:multivariate_bayes_k_spectra_relative_to_pi}
\end{figure}

The abundance of kaons relative to the abundance of pions can be seen in~\autoref{fig:multivariate_bayes_k_spectra_relative_to_pi}. The graph emphasizes the fact that particles abundances are unevenly distributed across the $p_t$-, $\cos(\Theta)$-plane. The additional information contained in the newly added variables may be used for an improved classification of the tracks.

\subsection{Comparison}
\label{subsec:bayesian_approach_comparison}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.4\textheight,keepaspectratio]{{{../res/charged 01/Diff Statistics: pi Identification via PID, via simple Bayes}}}
	\caption{Comparison of PPV, TPR and FPR for simple Bayes with legacy PID approach for identifying pions. The upper graph shows both rates of each approach separately using different colors, while the lower visualizes the ratio between the PPV's respectively the TPR's.}
	\label{fig:diff_stats_pi_identification_via_pid_via_simple_bayes}
\end{figure}

\autoref{fig:diff_stats_pi_identification_via_pid_via_simple_bayes} shows a comparison of the \textbf{legacy PID} approach to the \textbf{simple Bayes}ian one for identifying pions. The simple Bayesian approach is able to achieve a lot higher efficiencies at a low FPR. In addition the new approach provides a very high purity also at a very low FPR in a range where the legacy PID approach is not even able to identify pions. For a high FPR both approaches converge into similar shapes with rate ratios close to one.
The described effect can be seen for every stable particle with an ID and is not limited to the pion. The comparison of the pion identification is a rather conservative choice as the legacy PID approach favors high abundance particles and should have put it at an advantage. Particles like the electron or muon perform consistently better using the new approach even at false positive rates above $50\%$.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.3\textheight,keepaspectratio]{{{../res/charged 01/Diff Heatmap: Heatmap of epsilonPID Matrix for an exclusive Cut via PID, via simple Bayes}}}
	\caption{Comparison of the row-wised normed confusion matrix for simple Bayes with the legacy PID approach.}
	\label{fig:diff_heatmap_via_pid_via_simple_bayes}
\end{figure}

The improvements in the identification efficiencies are less obvious for an exclusive cut on the identifying variables. However in general the simple Bayesian approach is less prone to confusing particle with one another as seen in~\autoref{fig:diff_heatmap_via_pid_via_simple_bayes}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.3\textheight,keepaspectratio]{{{../res/charged 01/Diff Heatmap: Heatmap of epsilonPID Matrix for an exclusive Cut via global PID, via simple Bayes}}}
	\caption{Comparison of the row-wised normed confusion matrix for the global PID approach with simple Bayes.}
	\label{fig:diff_heatmap_via_global_pid_via_simple_bayes}
\end{figure}

The differences are less pronounced in comparison to the \textbf{global PID} variables as seen in~\autoref{fig:diff_heatmap_via_global_pid_via_simple_bayes}. At this point it becomes a question of the desired goal. The pion identification is boosted but only at the cost of loosing efficiency for the muon identification. At the same time the efficiencies for the kaon, electron and proton identification stayed about the same.

Overall, simple Bayes achieves a higher efficiency since kaons are particles of higher abundance. Therefore, in general it classifies more tracks correctly as seen in~\autoref{fig:diff_abundances_via_pid_via_global_pid_via_simple_bayes}. Of special interest is the good agreement of predicted and true particle abundances for the Bayesian approach as the information was built into it by design.

\begin{figure}[ht]
	\centering
	\subcaptionbox{PID, simple Bayes\label{fig:diff_abundances_via_pid_via_simple_bayes}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Diff Abundances: Particle Abundances in the K+-Data via PID, via simple Bayes}}}
	}
	\hspace{2em}
	\subcaptionbox{global PID, simple Bayes\label{fig:diff_abundances_via_pid_via_simple_bayes}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Diff Abundances: Particle Abundances in the K+-Data via global PID, via simple Bayes}}}
	}
	\caption{Counting from the top the first line of each approach (color coded) represents the abundance according to the approach, while the lower line represents the number of correctly classified particles. The particle classification hereby is exclusive.}
	\label{fig:diff_abundances_via_pid_via_global_pid_via_simple_bayes}
\end{figure}

Introducing more degrees of freedom in the form of the \textbf{univariate Bayes}ian approach reveals no difference . Using the pion again as conservative sample, the identification improves slightly as seen in~\autoref{fig:diff_stats_pi_identification_via_simple_bayes_via_univariate_bayes}. Although slightly less particles are classified overall which can be seen via the ratio of the TPRs being below $1.$, a boost of the rate of correctly classified particles more than compensates for the slight loss. The efficiencies for each particle identification further manifests this view although overall its behavior is very similar to the simple Bayesian one and a comparison between univariate Bayes and global PID respectively the legacy PID approach would therefore be redundant.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth,height=0.4\textheight,keepaspectratio]{{{../res/charged 01/Diff Statistics: pi Identification via simple Bayes, via univariate Bayes}}}
	\caption{Comparison of PPV, TPR and FPR for simple Bayes with univariate Bayes for identifying pions. The tail of the PPV ratio is due the ever decreasing PPV and the relative change getting bigger and does not necessarily allows for a conclusion of superiority.}
	\label{fig:diff_stats_pi_identification_via_simple_bayes_via_univariate_bayes}
\end{figure}

Lastly the \textbf{multivariate Bayes}ian approach is tested. Its TPR and PPV are identical to the univariate approach for every particle species in the sample --- neglecting effects below a maximal relative changes of $2 \%$. At this point it is important to emphasize that the change, albeit being small, improve results rather than worsen them; Negative effects in TPR and PPV are always below a threshold of $0.3 \cdot 10^{-3}$ while the maximal change of $2 \%$ slightly boosted the PPV for the muon identification at one point.
The similarity of the multivariate and univariate approach is also reflected in the efficiencies of the row-wised normed confusion matrix being virtually identical.

The global efficiencies over all particle species are displayed in~\autoref{tab:overall_efficiencies}.

\begin{table}[ht]
	\centering
	\begin{tabular}{l|l}
		Particle identification approach & Overall identification efficiency \\
		\hline
		legacy PID & $(844 \pm 4) \permille$ \\ % 0.841650, 0.840713, 0.841381, 0.840628, 0.848190, 0.848589, 0.848208, 0.848342
		global PID & $(792 \pm 2) \permille$ \\ % 0.790291, 0.790009, 0.790600, 0.790581, 0.793814, 0.793484, 0.794605, 0.793748
		simple Bayes & $(882 \pm 2) \permille$ \\ % 0.880800, 0.880086, 0.880715, 0.880286, 0.884530, 0.884318, 0.884664, 0.884109
		univariate Bayes & $(885 \pm 3) \permille$ \\ % 0.882854, 0.882183, 0.882980, 0.882411, 0.886828, 0.886719, 0.887014, 0.886597
		multivariate Bayes & $(885 \pm 3) \permille$ % 0.882964, 0.882461, 0.883159, 0.882591, 0.886961, 0.887016, 0.887171, 0.886819
	\end{tabular}
	\caption{Overall efficiencies for various particle identical approaches with their statistical error. Errors were estimated using four charged and four mixed generic decay files.}
	\label{tab:overall_efficiencies}
\end{table}


\subsection{Summary and outlook}
\label{subsc:bayesian_approach_summary}

In comparison to the legacy PID approach the positive effect introduced by the Bayesian approach are mainly due to inclusion of further particle likelihoods. Both the global PID approach as well as the Bayesian one decrease the rate at which particles of high abundance are identified. However both approaches in turn increase the identical efficiencies of particles with a low abundance significantly. Hereby, the Bayesian approach is able shine as it correctly classifies more pions correctly in the charged generic decay at the cost of a reduced identifying rate for some particles of lower abundance particles.

The difference between the simple Bayesian approach, the univariate Bayesian approach and the multivariate Bayesian approach is slim. Neither the overall identification efficiencies change significantly, nor does the identification rate of certain particles get boosted. Slight overall gains are measurable but insignificant.

As an outlook, further studies concerning the cell structure of the a priori probabilities are worth considering. The current approach of selecting equal height bins has been shown to be useful. Nevertheless, it is limited especially if used in conjunction with multiple other variables. Two intervals on separate variables, each containing a certain percent of the data, are not guaranteed to contain the same amount of data if intersected. A possible extension could be to implement a proper two dimensional clustering using, e.g., Voronoi cells (see~\cite{KnowledgeDiscoveryInDatabases1:Clustering}) instead of interval boundaries. Density based clustering algorithms such as DBSCAN and OPTICS (see~\cite{KnowledgeDiscoveryInDatabases1:Clustering}) might also be worth considering. Those approaches could further extend the a priori probabilities of the two dimensional cells of the multivariate Bayesian approach to density connected clusters.

Additionally overlapping boundaries either from the current approach or introduced by new clustering algorithms could be used to weight a priori probabilities. Instead of relying on one exclusive boundary, the mean of multiple a priori probabilities estimates could be used instead.

\section{Neural network approach}
\label{sec:neural_network_approach}

\subsection{Design}
\label{subsec:neural_network_design}

In the following discussion a neural networking consisting of sequential layers is chosen. As software library, Keras~\cite{chollet2015keras} is used with TensorFlow~\cite{tensorflow2015-whitepaper} as back-end.

Eight layers are found to perform best without over-fitting the data. Thereby, two different concepts for layers are used; On one hand a so called \textit{dense} layer connects all inputs with each node in the layers, as seen in~\autoref{fig:sample_neural_network_design}. It usually has a rather high number of free parameters depending on the used function in a node. On the other hand a so called \textit{dropout} layer was employed which as its name suggests drops a certain percentage of inputs by chance. It enforces the training to happen on only the remaining nodes. It is commonly used to counteract the effect of having a lot of free parameters as it randomly disregards values and therefore possibly drops nodes which would otherwise start to over-fit (see~\cite{MachineLearning:DeepLearning}).

Three different approaches for the choice of input parameters were evaluated. First the unaltered global PID variables for each detector are used as a baseline. As second approach a rich mixture of variables are used, containing information on the momentum, the angle between the beampipe and the track, the distance of the vertex to the interaction point, the energy, the curvature of the track, the charge, the legacy PIDs as well as the global PID variables for each detector. The third approach used the same initial inputs as the second one. However prior to passing the values to the network, a Principal Component Analysis (see~\cite{BigDataManagementAndAnalytics:TextProcessingAndHigh-DimensionalData}) on the standardized data was performed. The standardization step centers the data by removing the mean and scales the the value so that the standard deviation becomes one. It is an important pre-processing step as it counteracts the effect of having different units and scales for each variable.

The output, i.e., the actual classification, was done in the final step of the network via the previously discussed softmax algorithm using the gradient of the cross-entropy for weight adaption. In order to get a unique classification, the class with the highest softmax value was selected. As targets for classification the six long-living particle species were used with the addition of a zeroth class used for classifying particles which do not belong to the six other classes. This zeroth class includes just a fractional amount of particles but it is important to have it either way as each track on which the network is supposed to learn is required to have a target associated with it.

\autoref{tab:neural_network_parameters} shows the parametrization used for the network. Overall it has between $1,200$ and $1,800$ free parameters which are to be adapted, depending on the dimensionality of the input.

\begin{table}[ht]
	\centering
	\begin{tabular}{l|llll}
		Layer number & Type & Activation & Bias & \#Nodes  \\
		\hline
		1 & Dense & ReLU & True & 14 \\
		2 & Dropout ($20\%$) \\
		3 & Dense & ReLU & True & 21 \\
		4 & Dropout ($20\%$) \\
		5 & Dense & ReLU & True & 14 \\
		6 & Dropout ($20\%$) \\
		7 & Dense & ReLU & True & 10 \\
		8 & Dense & Softmax & True & 7
	\end{tabular}
	\caption{Design parameters of the neural network.}
	\label{tab:neural_network_parameters}
\end{table}

\subsection{Performance}
\label{subsec:neural_network_performance}

As performance measurement the accuracy is used. It is the fraction of correctly classified tracks relative to all available ones. In the discussed case it is synonymous to the overall efficiency.

Testing and validation is done using a fixed split between training and validation data (\textit{holdout method}). It is important to separate those two samples in order to spot networks which over-fit the data instead of actually `learning'. The training data is a random sample containing $80\%$ the number of tracks as the original data --- Note, this does not necessarily need to actually be $80\%$ of the data as some tracks can be picked multiple times. The remaining tracks are used for validating the actual learning process. Both training set and validation set are used to compute the accuracy however only the training sample is used to adapt weights. In the case of no over-fitting the validation accuracy fluctuates around the training accuracy.

Furthermore two approaches for sampling the data are analysed. One approach picks all tracks at random with equal weights and hence in theory has a bias towards particle species with a higher abundance. The other approach weights tracks in a way which make every particle specie equally likely to be picked (\textit{upsampling}).

Each training is performed with a batch size of $256$. Smaller batch sizes turn out to perform bad as the weights are adapted too frequently and the accuracy fluctuates without increasing overall. The current batch size is found via iteratively picking higher values until finding a rate at which the accuracy increases only gradually.

Furthermore several optimizers --- algorithms, describing the process of weight adaption --- are tested. In the end Adadelta (see~\cite{DBLP:journals/corr/abs-1212-5701}) and Adamax (see~\cite{DBLP:journals/corr/KingmaB14}) prove to have the best performance with the least fluctuations in the validation accuracy. Hence, the following discussion will focus on only those two weight adaption approaches.

\autoref{fig:neural_network_all_biased} shows the two optimizers in comparison. Both yield pretty similar results, especially considering the scaling of the accuracy. It is important to note that both are able to `learn' the classification problem rather quickly. Within the first epoch --- the first iteration through all the tracks --- both are able to achieve accuracies of about $90\%$. However, they level off rather quickly. After approximately $15$ iterations no noticeable change in the training accuracy can be observed. The validation accuracy follows the general trend of the training accuracy but as expected it shows a lot more fluctuation.

\begin{figure}[ht]
	\centering
	\subcaptionbox{Adadelta\label{fig:neural_network_all_biased_adadelta}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy all biased nLayers8 Optimizeradadelta LearningRateNone nEpochs15 BatchSize256}}}
	}
	\hspace{2em}
	\subcaptionbox{Adamax\label{fig:neural_network_all_biased_adamax}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy all biased nLayers8 Optimizeradamax LearningRateNone nEpochs15 BatchSize256}}}
	}
	\caption{Accuracy of the neural network using the Adadelta and Adamax optimizer with everything selected as features. The values are displayed for a biased sampling approach.}
	\label{fig:neural_network_all_biased}
\end{figure}

The high slope at which the accuracy initially increases even within the first epoch, can be observed independently of the sampling method and the feature selection.

\autoref{fig:neural_network_global_pid_by_sampling_method} compares the two sampling approaches. The graph employs the Adamax optimizer, however the Adadelta behaves similarly. One may observe that the network which receives the tracks of the particles in proportion to their abundance (biased sampling) is able to outperform the network which is trained on data using upsampling. The final difference in validation accuracy is about $4\%$.

\begin{figure}[ht]
	\centering
	\subcaptionbox{Biased\label{fig:neural_network_global_pid_biased_adamax}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy pidProbability biased nLayers8 Optimizeradamax LearningRateNone nEpochs15 BatchSize256}}}
	}
	\hspace{2em}
	\subcaptionbox{Upsampled\label{fig:neural_network_global_pid_fair_adamax}}{
		\includegraphics[width=0.4\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy pidProbability fair nLayers8 Optimizeradamax LearningRateNone nEpochs15 BatchSize256}}}
	}
	\caption{Accuracy of the neural network using the Adamax optimizer with the global PID as features. The values are displayed for a biased sampling approach (left) and the upsampling approach (right).}
	\label{fig:neural_network_global_pid_by_sampling_method}
\end{figure}

In~\autoref{fig:neural_network_pca_all} the PCA feature selection approach is shown next to the `all' approach. The term `all' in this context denotes that every available variable is selected as feature. As seen in the graph, the accuracy increases with the number of components and even surpasses the selection of all components. The values are considerable worse than the one which were calculated using biased sampling.

\begin{figure}[ht]
	\centering
	\subcaptionbox{`All'\label{fig:neural_network_all_fair_adamax}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy all fair nLayers8 Optimizeradamax LearningRateNone nEpochs15 BatchSize256}}}
	}
	\hspace{0.5em}
	\subcaptionbox{PCA, $50$ components\label{fig:neural_network_pca50_fair_adamax}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy pca ncomponents50 fair nLayers8 Optimizeradamax LearningRateNone nEpochs15 BatchSize256}}}
	}
	\hspace{0.5em}
	\subcaptionbox{PCA, $90$ components\label{fig:neural_network_pca90_fair_adamax}}{
		\includegraphics[width=0.3\textwidth,height=\textheight,keepaspectratio]{{{../res/charged 01/Neural Network Model: Accuracy pca ncomponents90 fair nLayers8 Optimizeradamax LearningRateNone nEpochs15 BatchSize256}}}
	}
	\caption{Accuracy of the neural network using the Adamax optimizer with selecting all features (left), the $50$ most principal components (center) and the $90$ most principal components (right). The values are displayed for a set using upsampling.}
	\label{fig:neural_network_pca_all}
\end{figure}
